{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "dataset_path = 'dataset2'  # Replace with your dataset path\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dataset_path):\n",
    "    # Create base directories\n",
    "    base_dir = os.path.dirname(dataset_path)\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    val_dir = os.path.join(base_dir, 'validation')\n",
    "    test_dir = os.path.join(base_dir, 'test')\n",
    "    \n",
    "    # Remove existing directories and recreate\n",
    "    for dir_path in [train_dir, val_dir, test_dir]:\n",
    "        if os.path.exists(dir_path):\n",
    "            shutil.rmtree(dir_path)\n",
    "        os.makedirs(dir_path)\n",
    "    \n",
    "    # Get class names (folders in the dataset path)\n",
    "    classes = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "    \n",
    "    # Split data for each class\n",
    "    for cls in classes:\n",
    "        cls_path = os.path.join(dataset_path, cls)\n",
    "        \n",
    "        # Get all image files\n",
    "        files = [f for f in os.listdir(cls_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
    "        \n",
    "        # Shuffle files\n",
    "        np.random.shuffle(files)\n",
    "        \n",
    "        # Calculate split indices\n",
    "        total_files = len(files)\n",
    "        train_split = int(0.7 * total_files)\n",
    "        val_split = train_split + int(0.2 * total_files)\n",
    "        \n",
    "        # Create class-specific directories\n",
    "        train_cls_dir = os.path.join(train_dir, cls)\n",
    "        val_cls_dir = os.path.join(val_dir, cls)\n",
    "        test_cls_dir = os.path.join(test_dir, cls)\n",
    "        \n",
    "        os.makedirs(train_cls_dir, exist_ok=True)\n",
    "        os.makedirs(val_cls_dir, exist_ok=True)\n",
    "        os.makedirs(test_cls_dir, exist_ok=True)\n",
    "        \n",
    "        # Copy files to respective directories\n",
    "        for i, file in enumerate(files):\n",
    "            src = os.path.join(cls_path, file)\n",
    "            if i < train_split:\n",
    "                dst = os.path.join(train_cls_dir, file)\n",
    "            elif i < val_split:\n",
    "                dst = os.path.join(val_cls_dir, file)\n",
    "            else:\n",
    "                dst = os.path.join(test_cls_dir, file)\n",
    "            \n",
    "            # Use copy instead of symlink\n",
    "            shutil.copy2(src, dst)\n",
    "    \n",
    "    return train_dir, val_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and generators\n",
    "def create_data_generators(train_dir, val_dir, test_dir):\n",
    "    # Training data generator with augmentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    \n",
    "    # Validation and test data generators (only rescaling)\n",
    "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # Create generators\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "    val_generator = val_test_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "    test_generator = val_test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "    # Load pre-trained DenseNet121\n",
    "    base_model = DenseNet121(\n",
    "        weights='imagenet', \n",
    "        include_top=False, \n",
    "        input_shape=(img_height, img_width, 3)\n",
    "    )\n",
    "    \n",
    "    # More conservative fine-tuning\n",
    "    # Only unfreeze the last few blocks\n",
    "    for layer in base_model.layers[:-20]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    for layer in base_model.layers[-20:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # Add regularization\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "    x = Dropout(0.5)(x)  # Add dropout for regularization\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# When compiling\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training function with fine-tuning specific configurations\n",
    "def train_model():\n",
    "    # Prepare data\n",
    "    train_dir, val_dir, test_dir = prepare_data(dataset_path)\n",
    "    \n",
    "    # Create data generators\n",
    "    train_generator, val_generator, test_generator = create_data_generators(\n",
    "        train_dir, val_dir, test_dir\n",
    "    )\n",
    "    \n",
    "    # Get number of classes\n",
    "    num_classes = len(train_generator.class_indices)\n",
    "    print(f\"Number of classes detected: {num_classes}\")\n",
    "    print(f\"Class indices: {train_generator.class_indices}\")\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model(num_classes)\n",
    "    \n",
    "    # Compile model with lower learning rate for fine-tuning\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-5),  # Lower learning rate for fine-tuning\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Callbacks\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        'best_densenet_finetuned_model.keras', \n",
    "        save_best_only=True, \n",
    "        monitor='val_accuracy'\n",
    "    )\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=10, \n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Learning rate reduction callback\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.2,  # Reduce learning rate by 80%\n",
    "        patience=5,  # Wait 5 epochs before reducing\n",
    "        min_lr=1e-6  # Minimum learning rate\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=5,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[checkpoint, early_stopping, reduce_lr]\n",
    "    )\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "    print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "    \n",
    "    # Save final model\n",
    "    model.save('final_densenet_finetuned_model.h5')\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6166 images belonging to 2 classes.\n",
      "Found 1761 images belonging to 2 classes.\n",
      "Found 882 images belonging to 2 classes.\n",
      "Number of classes detected: 2\n",
      "Class indices: {'cats': 0, 'dogs': 1}\n",
      "Epoch 1/5\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 2s/step - accuracy: 0.6091 - loss: 1.1903 - val_accuracy: 0.9478 - val_loss: 0.6083 - learning_rate: 1.0000e-05\n",
      "Epoch 2/5\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 2s/step - accuracy: 0.8452 - loss: 0.7385 - val_accuracy: 0.9727 - val_loss: 0.4929 - learning_rate: 1.0000e-05\n",
      "Epoch 3/5\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 2s/step - accuracy: 0.9068 - loss: 0.6094 - val_accuracy: 0.9807 - val_loss: 0.4481 - learning_rate: 1.0000e-05\n",
      "Epoch 4/5\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 2s/step - accuracy: 0.9338 - loss: 0.5395 - val_accuracy: 0.9835 - val_loss: 0.4176 - learning_rate: 1.0000e-05\n",
      "Epoch 5/5\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 2s/step - accuracy: 0.9402 - loss: 0.4992 - val_accuracy: 0.9847 - val_loss: 0.3973 - learning_rate: 1.0000e-05\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.9871 - loss: 0.3906\n",
      "Test Accuracy: 98.53%\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
